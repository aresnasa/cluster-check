# Kubernetesé›†ç¾¤å¥åº·æ£€æŸ¥å·¥å…· - æ›´æ–°æ—¥å¿—

## ç‰ˆæœ¬ 2.1.0 (2025-05-27)

### âœ¨ æ–°å¢åŠŸèƒ½

#### MasterèŠ‚ç‚¹æ£€æŸ¥å¢å¼º
- âœ… **etcdç‰ˆæœ¬æ£€æŸ¥**: æ·»åŠ äº†etcdæœåŠ¡çŠ¶æ€ã€ç‰ˆæœ¬ä¿¡æ¯æ£€æŸ¥
- âœ… **etcdå¥åº·æ£€æŸ¥**: æ”¯æŒetcdé›†ç¾¤å¥åº·çŠ¶æ€å’Œæˆå‘˜åˆ—è¡¨æ£€æŸ¥
- âœ… **etcd Podæ¨¡å¼æ£€æµ‹**: è‡ªåŠ¨æ£€æµ‹å’ŒæŠ¥å‘ŠStatic Podæ¨¡å¼çš„etcd
- âœ… **Masterç»„ä»¶çŠ¶æ€**: æ£€æŸ¥kube-apiserverã€kube-controller-managerã€kube-schedulerçŠ¶æ€
- âœ… **ç½‘ç»œç»„ä»¶æ£€æŸ¥**: è‡ªåŠ¨æ£€æµ‹CNIç½‘ç»œæ’ä»¶(Calicoã€Flannelã€Weaveç­‰)

#### WorkerèŠ‚ç‚¹ç³»ç»Ÿé…ç½®å®Œå–„
- âœ… **Cgroupç‰ˆæœ¬æ£€æŸ¥**: æ£€æµ‹å¹¶å»ºè®®Cgroup v1/v2ç‰ˆæœ¬
- âœ… **é˜²ç«å¢™çŠ¶æ€æ£€æŸ¥**: æ£€æŸ¥Firewalldå’ŒUFWçŠ¶æ€ï¼Œç¡®ä¿ç¬¦åˆK8sè¦æ±‚
- âœ… **SELinuxçŠ¶æ€æ£€æŸ¥**: éªŒè¯SELinuxç¦ç”¨çŠ¶æ€
- âœ… **SwapçŠ¶æ€æ£€æŸ¥**: ç¡®ä¿Swapå·²ç¦ç”¨
- âœ… **æ—¶åŒºé…ç½®æ£€æŸ¥**: éªŒè¯æ—¶åŒºè®¾ç½®ä¸ºAsia/Shanghai
- âœ… **æ—¶é—´åŒæ­¥æ£€æŸ¥**: æ£€æŸ¥Chronyd/NTPæœåŠ¡çŠ¶æ€
- âœ… **Kuberneteså†…æ ¸å‚æ•°**: éªŒè¯å…³é”®sysctlå‚æ•°é…ç½®
- âœ… **Kubernetesè½¯ä»¶åŒ…**: æ£€æŸ¥kubeletã€kubeadmã€kubectlç‰ˆæœ¬

#### GPU WorkerèŠ‚ç‚¹ä¸“é¡¹å¢å¼º
- âœ… **NVIDIAå†…æ ¸æ¨¡å—æ£€æŸ¥**: éªŒè¯NVIDIAé©±åŠ¨æ¨¡å—åŠ è½½çŠ¶æ€
- âœ… **DCGMå®Œæ•´æ”¯æŒ**: å¢å¼ºDCGM CLIã€DCGM Exporterã€Host Engineæ£€æŸ¥
- âœ… **GPUç¡¬ä»¶æ£€æµ‹**: é€šè¿‡lspciæ£€æµ‹æ˜¾å¡ç¡¬ä»¶
- âœ… **å®¹å™¨GPUæ”¯æŒ**: æ£€æŸ¥nvidia-dockerã€containerd GPUæ”¯æŒ

### ğŸ”§ æ”¹è¿›åŠŸèƒ½

#### æŠ¥å‘Šæ ¼å¼å¢å¼º
- âœ… **å®Œæ•´æ–‡æœ¬æ ¼å¼è¾“å‡º**: æ‰€æœ‰èŠ‚ç‚¹ç±»å‹éƒ½æ”¯æŒæ–‡æœ¬æ ¼å¼æŠ¥å‘Š
- âœ… **çŠ¶æ€æ ‡è¯†ä¼˜åŒ–**: ä½¿ç”¨âœ…âŒâš ï¸å›¾æ ‡æ¸…æ™°æ ‡è¯†æ£€æŸ¥çŠ¶æ€
- âœ… **æ£€æŸ¥ç»“æœåˆ†ç±»**: æŒ‰ç³»ç»Ÿé…ç½®ã€è½¯ä»¶åŒ…ã€ç»„ä»¶çŠ¶æ€ç­‰åˆ†ç±»å±•ç¤º

#### ç³»ç»Ÿå…¼å®¹æ€§
- âœ… **å¤šLinuxå‘è¡Œç‰ˆæ”¯æŒ**: æ”¹è¿›æ“ä½œç³»ç»Ÿæ£€æµ‹å…¼å®¹æ€§
- âœ… **å‘½ä»¤å¯ç”¨æ€§æ£€æŸ¥**: æ‰€æœ‰ç³»ç»Ÿå‘½ä»¤éƒ½æœ‰å¯ç”¨æ€§éªŒè¯
- âœ… **é”™è¯¯å¤„ç†å¢å¼º**: å‘½ä»¤æ‰§è¡Œå¤±è´¥æ—¶æä¾›å‹å¥½æç¤º

### ğŸ“ é¡¹ç›®ç»“æ„ä¼˜åŒ–

#### æ–‡ä»¶æ¸…ç†å’Œé‡ç»„
- ğŸ—‘ï¸ **åˆ é™¤å†—ä½™æ–‡æ¡£**: ç§»é™¤è¿‡æ—¶çš„æ ‡ç­¾è¯´æ˜å’Œå®ç°æ€»ç»“æ–‡æ¡£
- ğŸ—‘ï¸ **æ¸…ç†ä¸´æ—¶æ–‡ä»¶**: åˆ é™¤ç³»ç»Ÿç”Ÿæˆçš„.DS_Storeæ–‡ä»¶
- ğŸ“‹ **ç»“æ„æ–‡æ¡£åŒ–**: åˆ›å»ºPROJECT_STRUCTURE.mdè¯¦ç»†è¯´æ˜é¡¹ç›®ç»„ç»‡

#### æ¨¡æ¿æ–‡ä»¶å®Œå–„
- ğŸ“ **MasterèŠ‚ç‚¹æ¨¡æ¿**: å®Œå…¨é‡å†™master_check_script.sh.j2
- ğŸ“ **CPU Workeræ¨¡æ¿**: é‡æ–°åˆ›å»ºcpu_worker_check_script.sh.j2
- ğŸ“ **GPU Workeræ¨¡æ¿**: å¢å¼ºgpu_worker_check_script.sh.j2

### ğŸ” æ£€æŸ¥é¡¹ç›®è¯¦æƒ…

#### ç³»ç»Ÿé…ç½®æ£€æŸ¥ (æ‰€æœ‰èŠ‚ç‚¹)
```bash
# Cgroupç‰ˆæœ¬
/sys/fs/cgroup/unified (v2) æˆ– /sys/fs/cgroup/memory (v1)

# é˜²ç«å¢™çŠ¶æ€  
systemctl is-active firewalld
systemctl is-active ufw

# SELinuxçŠ¶æ€
getenforce

# SwapçŠ¶æ€
swapon --show

# æ—¶åŒºé…ç½®
timedatectl show --property=Timezone

# æ—¶é—´åŒæ­¥
systemctl is-active chronyd
systemctl is-active ntp

# å†…æ ¸å‚æ•°
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
net.ipv4.ip_forward = 1
vm.swappiness = 0
net.ipv4.conf.default.rp_filter = 1
net.ipv4.conf.all.rp_filter = 1
```

#### MasterèŠ‚ç‚¹ä¸“é¡¹æ£€æŸ¥
```bash
# etcdæ£€æŸ¥
systemctl is-active etcd
etcd --version
kubectl get pods -n kube-system -l component=etcd
etcdctl endpoint health
etcdctl member list

# Masterç»„ä»¶
kubectl get pods -n kube-system -l component=kube-apiserver
kubectl get pods -n kube-system -l component=kube-controller-manager  
kubectl get pods -n kube-system -l component=kube-scheduler

# ç½‘ç»œç»„ä»¶
kubectl get pods -n kube-system -l app=calico-node
kubectl get pods -n kube-system -l app=flannel
kubectl get pods -n kube-system -l app=weave-net
```

#### GPU Workerä¸“é¡¹æ£€æŸ¥
```bash
# NVIDIAæ£€æŸ¥
nvidia-smi
lsmod | grep nvidia
lspci | grep -i "vga\|3d\|display"

# DCGMæ£€æŸ¥
dcgmi discovery -l
dcgmi group -l  
dcgmi fieldgroup -l
dcgmi diag -r 1
dcgmi dmon -e 155,203,204,251,252,1001,1002,1003,1004,1005 -c 3
dcgmi health -v
systemctl status nv-hostengine

# å®¹å™¨GPUæ”¯æŒ
nvidia-docker --version
containerd --version
```

### ğŸ¯ ä½¿ç”¨æ–¹æ³•

#### æ‰§è¡Œå®Œæ•´æ£€æŸ¥
```bash
# æ£€æŸ¥æ‰€æœ‰èŠ‚ç‚¹ç±»å‹
ansible-playbook -i inventory_unified.ini unified_cluster_check_playbook_v2.yml

# ä»…æ£€æŸ¥MasterèŠ‚ç‚¹
ansible-playbook -i inventory_unified.ini unified_cluster_check_playbook_v2.yml --tags p1_master_check

# ä»…æ£€æŸ¥CPU WorkerèŠ‚ç‚¹  
ansible-playbook -i inventory_unified.ini unified_cluster_check_playbook_v2.yml --tags p2_cpu_worker_check

# ä»…æ£€æŸ¥GPU WorkerèŠ‚ç‚¹
ansible-playbook -i inventory_unified.ini unified_cluster_check_playbook_v2.yml --tags p3_gpu_worker_check
```

#### ç”Ÿæˆç»Ÿä¸€æŠ¥å‘Š
```bash
# ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š
./generate_unified_report.sh

# è¯Šæ–­å’Œä¿®å¤
./diagnose_and_fix.sh
```

### ğŸ“Š è¾“å‡ºæ ¼å¼

#### HTMLæŠ¥å‘Šç‰¹æ€§
- ğŸ¨ ç°ä»£åŒ–å“åº”å¼è®¾è®¡
- ğŸ“± ç§»åŠ¨ç«¯å‹å¥½æ˜¾ç¤º
- ğŸ” è¯¦ç»†çš„å‘½ä»¤è¾“å‡ºå±•ç¤º
- ğŸ¯ çŠ¶æ€é¢œè‰²ç¼–ç (ç»¿è‰²=æ­£å¸¸ï¼Œé»„è‰²=è­¦å‘Šï¼Œçº¢è‰²=é”™è¯¯)
- ğŸ“ˆ èµ„æºä½¿ç”¨æƒ…å†µå›¾è¡¨

#### æ–‡æœ¬æŠ¥å‘Šç‰¹æ€§  
- âœ… æ¸…æ™°çš„çŠ¶æ€å›¾æ ‡
- ğŸ“‹ åˆ†ç±»ç»„ç»‡çš„æ£€æŸ¥ç»“æœ
- ğŸ” å…³é”®ä¿¡æ¯æ‘˜è¦
- âš¡ å¿«é€Ÿé—®é¢˜è¯†åˆ«

### ğŸš€ æ€§èƒ½ä¼˜åŒ–

- âš¡ **å¹¶è¡Œæ‰§è¡Œ**: MasterèŠ‚ç‚¹å¹¶è¡Œåº¦3ï¼ŒCPU Workerå¹¶è¡Œåº¦5ï¼ŒGPU Workerå¹¶è¡Œåº¦3
- ğŸ”„ **é”™è¯¯å®¹å¿**: å•èŠ‚ç‚¹æ£€æŸ¥å¤±è´¥ä¸å½±å“å…¶ä»–èŠ‚ç‚¹
- ğŸ“¦ **æ¨¡æ¿ä¼˜åŒ–**: è¿œç¨‹ç”Ÿæˆè„šæœ¬ï¼Œå‡å°‘ç½‘ç»œä¼ è¾“
- ğŸ§¹ **è‡ªåŠ¨æ¸…ç†**: æ£€æŸ¥å®Œæˆåè‡ªåŠ¨æ¸…ç†ä¸´æ—¶æ–‡ä»¶

### ğŸ› ï¸ å…¼å®¹æ€§è¯´æ˜

#### æ”¯æŒçš„æ“ä½œç³»ç»Ÿ
- CentOS 7/8/9
- RHEL 7/8/9  
- Ubuntu 18.04/20.04/22.04
- Debian 10/11/12

#### æ”¯æŒçš„Kubernetesç‰ˆæœ¬
- Kubernetes 1.20+
- å…¼å®¹kubeadméƒ¨ç½²çš„é›†ç¾¤
- æ”¯æŒStatic Podå’ŒSystemdæœåŠ¡æ¨¡å¼

#### æ”¯æŒçš„GPUç¯å¢ƒ
- NVIDIA GPU + CUDAé©±åŠ¨
- NVIDIA Docker Runtime
- DCGM 2.0+ (å¯é€‰)
- Containerd GPUæ”¯æŒ

### ğŸ“ æ³¨æ„äº‹é¡¹

1. **æƒé™è¦æ±‚**: æ£€æŸ¥è„šæœ¬éœ€è¦sudoæƒé™æ‰§è¡Œç³»ç»Ÿå‘½ä»¤
2. **ç½‘ç»œè¦æ±‚**: éœ€è¦è®¿é—®Kubernetes API Server
3. **DCGMå¯é€‰**: DCGMä¸æ˜¯å¿…éœ€çš„ï¼Œä½†å»ºè®®GPUèŠ‚ç‚¹å®‰è£…ä»¥è·å¾—æ›´å¥½çš„ç›‘æ§
4. **etcdctlé…ç½®**: etcdå¥åº·æ£€æŸ¥å¯èƒ½éœ€è¦è¯ä¹¦é…ç½®

### ğŸ”— ç›¸å…³æ–‡æ¡£

- [PROJECT_STRUCTURE.md](./PROJECT_STRUCTURE.md) - é¡¹ç›®ç»“æ„è¯´æ˜
- [README.md](./README.md) - ä½¿ç”¨æŒ‡å—
- [inventory_unified.ini](./inventory_unified.ini) - èŠ‚ç‚¹é…ç½®ç¤ºä¾‹
